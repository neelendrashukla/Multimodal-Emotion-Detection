# Multimodal Emotion Detection
**Description**: A hybrid deep learning model to detect emotions from text, audio, and facial images, achieving 87.4% accuracy on 18,000 samples.
**Tech Stack**: Python, TensorFlow, PyTorch, BERT, ResNet-18, Librosa
**Results**: Integrated BERT for text, ResNet-18 for images, and MFCCs for audio.
**How It Works**:
- Preprocessed text with BERT, images with ResNet-18, and audio with MFCCs.
- Combined features for multimodal emotion classification.
- Evaluated with accuracy and F1-score on a balanced dataset.
